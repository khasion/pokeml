{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import albumentations as A\n",
    "from IPython.display import display\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# Configuration\n",
    "# ======================\n",
    "TARGET_SIZE = (128, 128)\n",
    "HOG_ORIENTATIONS = 9\n",
    "HOG_PIXELS_PER_CELL = (8, 8)\n",
    "HOG_CELLS_PER_BLOCK = (2, 2)\n",
    "COLOR_BINS = 64  # Increased from 32\n",
    "SIFT_CLUSTERS = 50\n",
    "\n",
    "# Toggle PCA usage. (Sometimes disabling PCA helps when using handcrafted features.)\n",
    "USE_PCA = False  # Try setting to False if needed\n",
    "# Toggle SIFT\n",
    "USE_SIFT = True\n",
    "# Adjust the threshold probability for multi-class predictions during inference.\n",
    "THRESHOLD_PROB = 0.10  # Lowering from 0.2 may yield more detections\n",
    "# Toggle Image Augmentation\n",
    "USE_AUG = True\n",
    "\n",
    "# Toggle hyperparameter tuning\n",
    "DO_HYPERPARAMETER_TUNING = True\n",
    "\n",
    "# Path configurations\n",
    "POKEMON_DIR = 'pokemon-data'\n",
    "NO_POKEMON_DIR = 'no-pokemon'\n",
    "MODEL_SAVE_DIR = 'models'\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Data Augmentation Pipeline\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=90, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.GaussNoise(p=0.5),\n",
    "    A.Resize(height=TARGET_SIZE[0], width=TARGET_SIZE[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(img, target_size=TARGET_SIZE):\n",
    "    \"\"\"\n",
    "    Reads an image from disk, ensures it is 8-bit RGB, and resizes it to the target size.\n",
    "    This function should be used during both training and inference.\n",
    "    \"\"\"\n",
    "    if img is None:\n",
    "        return None\n",
    "    \n",
    "    if img.dtype != np.uint8:\n",
    "        img = cv2.convertScaleAbs(img)\n",
    "    # Convert BGR to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # Resize the image\n",
    "\n",
    "    img = cv2.resize(img, target_size)\n",
    "    return img\n",
    "\n",
    "def load_images(path, target_size=TARGET_SIZE):\n",
    "    images = []\n",
    "    for fname in os.listdir(path):\n",
    "        img_path = os.path.join(path, fname)\n",
    "        # Read image with unchanged flag to capture any alpha channels or unusual bit depths\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "        img = transform_image(img)\n",
    "        if img is not None:\n",
    "            if USE_AUG:\n",
    "                augmented = transform(image=img)\n",
    "                augmented_img = augmented['image']\n",
    "                images.append(augmented_img)      \n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# Load and Transform Images for each class\n",
    "# ======================\n",
    "multi_images = []\n",
    "multi_labels = []\n",
    "for pname in os.listdir(POKEMON_DIR):\n",
    "    imgs = load_images(os.path.join(POKEMON_DIR, pname))\n",
    "    multi_images += imgs\n",
    "    multi_labels += [pname] * len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(multi_images)\n",
    "display(Image.fromarray(multi_images[3181]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# Feature Extraction\n",
    "# ======================\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, sift_kmeans=None):\n",
    "        if USE_SIFT:\n",
    "            self.sift = cv2.SIFT_create()\n",
    "            self.kmeans = sift_kmeans\n",
    "        self.scaler_bin = StandardScaler()\n",
    "        self.scaler_multi = StandardScaler()\n",
    "\n",
    "    def extract_basic_features(self, img):\n",
    "        \"\"\"Enhanced color-aware feature extraction\"\"\"\n",
    "        # --- HOG Features (Multi-channel) ---\n",
    "        hog_features = []\n",
    "        for channel in range(3):\n",
    "            # Using block normalization 'L2-Hys'\n",
    "            hog_feat = hog(\n",
    "                img[:, :, channel],\n",
    "                orientations=HOG_ORIENTATIONS,\n",
    "                pixels_per_cell=HOG_PIXELS_PER_CELL,\n",
    "                cells_per_block=HOG_CELLS_PER_BLOCK,\n",
    "                block_norm='L2-Hys'\n",
    "            )\n",
    "            hog_features.append(hog_feat)\n",
    "        hog_features = np.concatenate(hog_features)\n",
    "        \n",
    "        # --- LBP Features ---\n",
    "        # Convert to LAB for robust texture representation.\n",
    "        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "        lbp_features = []\n",
    "        P = 8  # Number of circularly symmetric neighbor set points\n",
    "        R = 1  # Radius\n",
    "        n_bins_lbp = P + 2  # For uniform patterns\n",
    "        for channel in range(3):\n",
    "            lbp = local_binary_pattern(lab[:, :, channel], P=P, R=R, method='uniform')\n",
    "            # Use the appropriate number of bins for uniform LBP\n",
    "            hist, _ = np.histogram(lbp.ravel(), bins=n_bins_lbp, range=(0, n_bins_lbp))\n",
    "            # Normalize histogram to have unit sum\n",
    "            hist = hist.astype('float')\n",
    "            hist /= (hist.sum() + 1e-7)\n",
    "            lbp_features.append(hist)\n",
    "        lbp_features = np.concatenate(lbp_features)\n",
    "        \n",
    "        # --- Color Histograms ---\n",
    "        # Compute histograms in both HSV and LAB color spaces.\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        color_features = []\n",
    "        \n",
    "        # HSV histograms:\n",
    "        # Note: OpenCV represents H in the range [0,180] for 8-bit images.\n",
    "        h_hist, _ = np.histogram(hsv[:, :, 0].ravel(), bins=COLOR_BINS, range=(0, 180))\n",
    "        s_hist, _ = np.histogram(hsv[:, :, 1].ravel(), bins=COLOR_BINS, range=(0, 256))\n",
    "        v_hist, _ = np.histogram(hsv[:, :, 2].ravel(), bins=COLOR_BINS, range=(0, 256))\n",
    "        # Normalize each histogram\n",
    "        h_hist = h_hist.astype('float') / (h_hist.sum() + 1e-7)\n",
    "        s_hist = s_hist.astype('float') / (s_hist.sum() + 1e-7)\n",
    "        v_hist = v_hist.astype('float') / (v_hist.sum() + 1e-7)\n",
    "        color_features.extend([h_hist, s_hist, v_hist])\n",
    "        \n",
    "        # LAB histograms:\n",
    "        for channel in range(3):\n",
    "            lab_hist, _ = np.histogram(lab[:, :, channel].ravel(), bins=COLOR_BINS, range=(0, 256))\n",
    "            lab_hist = lab_hist.astype('float') / (lab_hist.sum() + 1e-7)\n",
    "            color_features.append(lab_hist)\n",
    "        color_features = np.concatenate(color_features)\n",
    "        \n",
    "        # --- Final Feature Vector ---\n",
    "        return np.concatenate([hog_features, lbp_features, color_features])\n",
    "\n",
    "    def extract_sift_features(self, img):\n",
    "        \"\"\"Color-enhanced SIFT using dominant color channel.\n",
    "           Note: Consider using a dense sampling strategy if keypoint detection is too sparse.\n",
    "        \"\"\"\n",
    "        variances = [np.var(img[:, :, i]) for i in range(3)]\n",
    "        dominant_channel = np.argmax(variances)\n",
    "        _, des = self.sift.detectAndCompute(img[:, :, dominant_channel], None)\n",
    "        if des is None or len(des) < 5:\n",
    "            return np.zeros(SIFT_CLUSTERS)\n",
    "        clusters = self.kmeans.predict(des)\n",
    "        return np.bincount(clusters, minlength=SIFT_CLUSTERS)\n",
    "\n",
    "    def extract_all_features(self, img):\n",
    "        basic = self.extract_basic_features(img)\n",
    "        if USE_SIFT:\n",
    "            sift = self.extract_sift_features(img)\n",
    "            return np.hstack([basic, sift])\n",
    "        return np.hstack([basic])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# Training Pipeline\n",
    "# ======================\n",
    "def train_sift_codebook(images):\n",
    "    sift = cv2.SIFT_create()\n",
    "    descriptors = []\n",
    "    \n",
    "    for img in images:\n",
    "        variances = [np.var(img[:, :, i]) for i in range(3)]\n",
    "        dominant_channel = np.argmax(variances)\n",
    "        _, des = sift.detectAndCompute(img[:, :, dominant_channel], None)\n",
    "        if des is not None:\n",
    "            descriptors.append(des)\n",
    "    \n",
    "    if len(descriptors) == 0:\n",
    "        raise ValueError(\"No SIFT descriptors found in any image!\")\n",
    "    \n",
    "    all_descriptors = np.vstack(descriptors)\n",
    "    kmeans = MiniBatchKMeans(n_clusters=SIFT_CLUSTERS, random_state=42)\n",
    "    kmeans.fit(all_descriptors)\n",
    "    return kmeans\n",
    "\n",
    "if USE_SIFT:\n",
    "    print(\"Training SIFT codebook...\")\n",
    "    sift_kmeans = train_sift_codebook(multi_images)\n",
    "    joblib.dump(sift_kmeans, os.path.join(MODEL_SAVE_DIR, 'sift_kmeans.pkl'))\n",
    "            # Initialize feature extractor        \n",
    "    fe = FeatureExtractor(sift_kmeans)\n",
    "else:\n",
    "    fe = FeatureExtractor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# Feature Extraction for Multi-class Classification\n",
    "# ======================\n",
    "print(\"\\nTraining multi-class classifiers...\")\n",
    "le = LabelEncoder()\n",
    "y_multi = le.fit_transform(multi_labels)\n",
    "    \n",
    "print(\"Extracting features...\")\n",
    "X_multi = [fe.extract_all_features(img) for img in tqdm(multi_images, desc='Processing images')]\n",
    "X_multi = fe.scaler_multi.fit_transform(X_multi)\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
    "X_multi, y_multi, test_size=0.2, stratify=y_multi, random_state=42)\n",
    "\n",
    "pca_multi = None\n",
    "if USE_PCA:\n",
    "    pca_multi = PCA(n_components=0.95, random_state=42)\n",
    "    X_train_multi = pca_multi.fit_transform(X_train_multi)\n",
    "    X_test_multi = pca_multi.transform(X_test_multi)\n",
    "    joblib.dump(pca_multi, os.path.join(MODEL_SAVE_DIR, 'pca_multi.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multi-class models along with their parameter grids.\n",
    "models = {\n",
    "'XGBoost': (XGBClassifier(random_state=42), {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}),\n",
    "'SVM-RBF': (SVC(kernel='rbf', probability=True, random_state=42, class_weight='balanced'), {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale']\n",
    "}),\n",
    "'kNN': (KNeighborsClassifier(weights='distance'), {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}),\n",
    "'RForest': (RandomForestClassifier(random_state=42, class_weight='balanced'), {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'max_features': ['sqrt']\n",
    "})\n",
    "}\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    if DO_HYPERPARAMETER_TUNING:\n",
    "        print(f\"\\nTuning {model_name}...\")\n",
    "        grid = GridSearchCV(\n",
    "            model, param_grid, cv=3, scoring='accuracy', n_jobs=2, verbose=2\n",
    "        )\n",
    "        grid.fit(X_train_multi, y_train_multi)\n",
    "        print(f\"Best parameters for {model_name}:\", grid.best_params_)\n",
    "        best_model = grid.best_estimator_\n",
    "    else:\n",
    "        best_model = model.fit(X_train_multi, y_train_multi)\n",
    "    \n",
    "    y_pred = best_model.predict(X_test_multi)\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(classification_report(le.inverse_transform(y_test_multi), \n",
    "                                le.inverse_transform(y_pred)))\n",
    "      \n",
    "    joblib.dump(best_model, os.path.join(MODEL_SAVE_DIR, f'multi_clf_{model_name.lower()}.pkl'))\n",
    "\n",
    "joblib.dump(fe.scaler_bin, os.path.join(MODEL_SAVE_DIR, 'scaler_bin.pkl'))\n",
    "joblib.dump(fe.scaler_multi, os.path.join(MODEL_SAVE_DIR, 'scaler_multi.pkl'))\n",
    "joblib.dump(le, os.path.join(MODEL_SAVE_DIR, 'label_encoder.pkl'))\n",
    "    \n",
    "print(\"\\nTraining complete! Models saved to:\", MODEL_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# Inference Pipeline\n",
    "# ======================\n",
    "class PokemonDetector:\n",
    "    def __init__(self, model_name='rforest'):\n",
    "        if USE_SIFT:\n",
    "            self.sift_kmeans = joblib.load(os.path.join(MODEL_SAVE_DIR, 'sift_kmeans.pkl'))\n",
    "            self.fe = FeatureExtractor(self.sift_kmeans)\n",
    "        else:\n",
    "            self.fe = FeatureExtractor()\n",
    "        self.binary_clf = joblib.load(os.path.join(MODEL_SAVE_DIR, 'binary_clf.pkl'))\n",
    "        self.multi_clf = joblib.load(os.path.join(MODEL_SAVE_DIR, f'multi_clf_{model_name.lower()}.pkl'))\n",
    "        self.le = joblib.load(os.path.join(MODEL_SAVE_DIR, 'label_encoder.pkl'))\n",
    "        self.scaler_bin = joblib.load(os.path.join(MODEL_SAVE_DIR, 'scaler_bin.pkl'))\n",
    "        self.scaler_multi = joblib.load(os.path.join(MODEL_SAVE_DIR, 'scaler_multi.pkl'))\n",
    "        \n",
    "        self.use_pca = USE_PCA\n",
    "        if self.use_pca:\n",
    "            self.pca_bin = joblib.load(os.path.join(MODEL_SAVE_DIR, 'pca_bin.pkl'))\n",
    "            self.pca_multi = joblib.load(os.path.join(MODEL_SAVE_DIR, 'pca_multi.pkl'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
